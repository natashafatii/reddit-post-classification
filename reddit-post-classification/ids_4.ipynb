{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdBnT6zJYXnA",
        "outputId": "b21237e0-6684-4c79-ee2d-fae29616b132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.12/dist-packages (7.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.12/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.12/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from praw) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from prawcore<3,>=2.4->praw) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install praw pandas python-dotenv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetching Reddit Data via API\n",
        "\n",
        "This section demonstrates how we collected data from Reddit programmatically using the **PRAW (Python Reddit API Wrapper)** library. The process involves connecting to the Reddit API, fetching posts from selected subreddits, and storing the data in a structured format.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **API Connection:**  \n",
        "   - Load Reddit API credentials from environment variables (`CLIENT_ID`, `CLIENT_SECRET`, `USER_AGENT`).  \n",
        "   - Establish a read-only connection to Reddit using `praw.Reddit()`.\n",
        "\n",
        "2. **Subreddit Selection:**  \n",
        "   - The script targets multiple subreddits: `r/technology`, `r/mentalhealth`, and `r/AskReddit`.  \n",
        "   - For each subreddit, it fetches **20 posts**, ignoring stickied posts.\n",
        "\n",
        "3. **Data Collection:**  \n",
        "   For each post, the following information is extracted:\n",
        "   - **Title**\n",
        "   - **Body**\n",
        "   - **Author**\n",
        "   - **Number of upvotes**\n",
        "   - **Number of comments**\n",
        "   - **Timestamp (UTC)**\n",
        "\n",
        "4. **Data Storage and Export:**  \n",
        "   - All collected posts are stored in a **Pandas DataFrame** for easy manipulation.  \n",
        "   - Data is sorted by subreddit and upvotes for a cleaner preview.  \n",
        "   - The raw data is exported to `raw_reddit_data.csv`.\n"
      ],
      "metadata": {
        "id": "oOBDbK1Tl6s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger(\"praw\").setLevel(logging.ERROR)\n",
        "import praw\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "CLIENT_ID = os.getenv(\"REDDIT_CLIENT_ID\")\n",
        "CLIENT_SECRET = os.getenv(\"REDDIT_CLIENT_SECRET\")\n",
        "USER_AGENT = os.getenv(\"REDDIT_USER_AGENT\")\n",
        "\n",
        "# Basic check for credentials\n",
        "if not CLIENT_ID or not CLIENT_SECRET or not USER_AGENT:\n",
        "    raise ValueError(\"Reddit API credentials are missing in the environment variables.\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\" Connecting to Reddit API...\")\n",
        "reddit = praw.Reddit(client_id=CLIENT_ID,\n",
        "                     client_secret=CLIENT_SECRET,\n",
        "                     user_agent=USER_AGENT)\n",
        "reddit.read_only = True\n",
        "print(\" Connected successfully!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Subreddits & posts config\n",
        "subreddits = [\"technology\", \"mentalhealth\", \"AskReddit\"]\n",
        "posts_per_subreddit = 20\n",
        "all_posts = []\n",
        "\n",
        "# Fetch posts\n",
        "for sub in subreddits:\n",
        "    print(f\"\\n Fetching {posts_per_subreddit} posts from r/{sub}...\")\n",
        "    subreddit_posts = []\n",
        "\n",
        "    for post in reddit.subreddit(sub).hot(limit=posts_per_subreddit + 5):  # extra in case of stickied\n",
        "        if post.stickied:\n",
        "            continue\n",
        "\n",
        "        author_name = str(post.author) if post.author else \"[deleted]\"\n",
        "        body_text = post.selftext if post.selftext else \"\"\n",
        "\n",
        "        # Collect post\n",
        "        post_data = {\n",
        "            \"subreddit\": sub,\n",
        "            \"title\": post.title,\n",
        "            \"body\": body_text,\n",
        "            \"author\": author_name,\n",
        "            \"upvotes\": post.score,\n",
        "            \"num_comments\": post.num_comments,\n",
        "            \"timestamp\": datetime.fromtimestamp(post.created_utc, tz=timezone.utc)\n",
        "        }\n",
        "        subreddit_posts.append(post_data)\n",
        "\n",
        "        # Print all posts (or first 20)\n",
        "        if len(subreddit_posts) <= posts_per_subreddit:\n",
        "            print(f\"\\n POST #{len(subreddit_posts)}\")\n",
        "            print(f\"Title: {post.title}\")\n",
        "            print(f\"Author: {author_name}\")\n",
        "            print(f\"Upvotes: {post.score} | Comments: {post.num_comments}\")\n",
        "            print(f\"Timestamp (UTC): {post_data['timestamp']}\")\n",
        "            print(f\"Body Preview: {body_text[:150].replace(chr(10),' ')}{'...' if len(body_text) > 150 else ''}\")\n",
        "\n",
        "        # Stop when we have enough posts\n",
        "        if len(subreddit_posts) >= posts_per_subreddit:\n",
        "            break\n",
        "\n",
        "    all_posts.extend(subreddit_posts)\n",
        "    print(f\" Collected {len(subreddit_posts)} posts from r/{sub}\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_posts, columns=[\n",
        "    \"subreddit\",\"title\",\"body\",\"author\",\"upvotes\",\"num_comments\",\"timestamp\"\n",
        "])\n",
        "\n",
        "# sort by subreddit then upvotes descending for better preview\n",
        "df.sort_values(by=[\"subreddit\",\"upvotes\"], ascending=[True, False], inplace=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" Raw Reddit Data Preview (First 10 rows) \")\n",
        "print(\"=\"*70)\n",
        "print(df.head(10).to_string(index=False))\n",
        "\n",
        "# Save CSV\n",
        "csv_filename = \"raw_reddit_data.csv\"\n",
        "df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n",
        "print(f\"\\n Saved {csv_filename} successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1MQ9iEfyWCw",
        "outputId": "5053b475-72b4-4587-c463-34dd2d3df34c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " Connecting to Reddit API...\n",
            " Connected successfully!\n",
            "======================================================================\n",
            "\n",
            " Fetching 20 posts from r/technology...\n",
            "\n",
            " POST #1\n",
            "Title: IBM CEO says there is 'no way' spending trillions on AI data centers will pay off at today's infrastructure costs\n",
            "Author: captain-price-\n",
            "Upvotes: 17768 | Comments: 1465\n",
            "Timestamp (UTC): 2025-12-02 15:04:53+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #2\n",
            "Title: More than 1,000 Amazon employees sign open letter warning the companyâ€™s AI â€˜will do staggering damage to democracy, our jobs, and the earthâ€™\n",
            "Author: Moonskaraos\n",
            "Upvotes: 1351 | Comments: 43\n",
            "Timestamp (UTC): 2025-12-02 18:19:53+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #3\n",
            "Title: Zig quits GitHub, says Microsoft's AI obsession has ruined the service\n",
            "Author: rkhunter_\n",
            "Upvotes: 538 | Comments: 14\n",
            "Timestamp (UTC): 2025-12-02 19:24:22+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #4\n",
            "Title: The rise of deepfake pornography in schools: â€˜One girl was so horrified she vomitedâ€™ | The use of â€˜nudifyâ€™ apps is becoming more and more prevalent, with hundreds of teachers having seen images created by pupils, often of their peers. The fallout is huge â€“ and growing fast\n",
            "Author: Hrmbee\n",
            "Upvotes: 1043 | Comments: 209\n",
            "Timestamp (UTC): 2025-12-02 15:26:43+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #5\n",
            "Title: Sundar Pichai says Google will start building data centers in space, powered by the sun, in 2027\n",
            "Author: rkhunter_\n",
            "Upvotes: 3653 | Comments: 856\n",
            "Timestamp (UTC): 2025-12-02 08:25:16+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #6\n",
            "Title: OpenAI Loses Discovery Battle, Cedes Ground to Authors in AI Lawsuits | The issue has been a major battleground in discovery. OpenAI could be on the hook for hundreds of millions, if not billions, of dollars if it was aware it was infringing on copyrighted material.\n",
            "Author: MetaKnowing\n",
            "Upvotes: 991 | Comments: 99\n",
            "Timestamp (UTC): 2025-12-02 14:56:30+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #7\n",
            "Title: A history professor says AI didn't break college â€” it exposed how broken it already was\n",
            "Author: joe4942\n",
            "Upvotes: 7199 | Comments: 558\n",
            "Timestamp (UTC): 2025-12-02 03:37:25+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #8\n",
            "Title: White House Launches Worthless And Whiny Taxpayer-Funded â€˜Media Biasâ€™ Tracker\n",
            "Author: StraightedgexLiberal\n",
            "Upvotes: 335 | Comments: 17\n",
            "Timestamp (UTC): 2025-12-02 18:43:46+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #9\n",
            "Title: â€˜Security Disasterâ€™â€”500 Million Microsoft Users Say No To Windows 11\n",
            "Author: MarvelsGrantMan136\n",
            "Upvotes: 21414 | Comments: 3469\n",
            "Timestamp (UTC): 2025-12-01 21:29:29+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #10\n",
            "Title: Users scramble as critical open source project left to die\n",
            "Author: collogue\n",
            "Upvotes: 1229 | Comments: 157\n",
            "Timestamp (UTC): 2025-12-02 09:46:24+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #11\n",
            "Title: Spider silk is no longer considered the strongest natural fiber. Japanese researchers have discovered that bagworm silk is actually stronger.\n",
            "Author: This-Temporary-835\n",
            "Upvotes: 362 | Comments: 29\n",
            "Timestamp (UTC): 2025-12-02 16:03:02+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #12\n",
            "Title: OpenAI declares â€˜code redâ€™ as Google catches up in AI race\n",
            "Author: TripleShotPls\n",
            "Upvotes: 668 | Comments: 217\n",
            "Timestamp (UTC): 2025-12-02 12:10:12+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #13\n",
            "Title: Apple refuses Indiaâ€™s order to preload state cyber safety app Sanchar Saathi, cites privacy risks\n",
            "Author: WhyohTee\n",
            "Upvotes: 938 | Comments: 54\n",
            "Timestamp (UTC): 2025-12-02 09:54:35+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #14\n",
            "Title: The â€˜rage-baitâ€™ era â€“ how AI is twisting our emotions without us even realising it\n",
            "Author: Disastrous_Award_789\n",
            "Upvotes: 205 | Comments: 39\n",
            "Timestamp (UTC): 2025-12-02 17:32:00+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #15\n",
            "Title: Half of the US Now Requires You to Upload Your ID or Scan Your Face to Watch Porn | Missouriâ€™s age verification law, enacted on November 30, is the halfway mark for the sweep of age verification laws across the country.\n",
            "Author: ControlCAD\n",
            "Upvotes: 137 | Comments: 53\n",
            "Timestamp (UTC): 2025-12-02 20:02:28+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #16\n",
            "Title: Instagram chief Adam Mosseri's memo ordering staff to the office five days a week in 2026\n",
            "Author: play3xxx1\n",
            "Upvotes: 4577 | Comments: 437\n",
            "Timestamp (UTC): 2025-12-01 23:20:55+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #17\n",
            "Title: Rockstar co-founder compares AI to 'mad cow disease,' and says the execs pushing it aren't 'fully-rounded humans'\n",
            "Author: kwentongskyblue\n",
            "Upvotes: 40243 | Comments: 1322\n",
            "Timestamp (UTC): 2025-12-01 16:26:01+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #18\n",
            "Title: Spotify stands by ICE recruitment ads despite artist backlash\n",
            "Author: Merlin_the_Lizard\n",
            "Upvotes: 7432 | Comments: 626\n",
            "Timestamp (UTC): 2025-12-01 19:32:48+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #19\n",
            "Title: Subaru Owners Are Ticked About In-Car Pop-Up Ads for SiriusXM\n",
            "Author: TripleShotPls\n",
            "Upvotes: 99 | Comments: 8\n",
            "Timestamp (UTC): 2025-12-02 18:14:33+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #20\n",
            "Title: Does Gen Z \"rawdogging boredom\" trend actually fix your attention span?\n",
            "Author: Disastrous_Award_789\n",
            "Upvotes: 7599 | Comments: 860\n",
            "Timestamp (UTC): 2025-12-01 17:27:07+00:00\n",
            "Body Preview: \n",
            " Collected 20 posts from r/technology\n",
            "\n",
            " Fetching 20 posts from r/mentalhealth...\n",
            "\n",
            " POST #1\n",
            "Title: Are men under 30 ruined?\n",
            "Author: [deleted]\n",
            "Upvotes: 171 | Comments: 131\n",
            "Timestamp (UTC): 2025-12-02 07:17:07+00:00\n",
            "Body Preview: Iâ€™m in my early 50s. White dude from a small farm town. My generation had its problems. Divorce. Alcoholism. Drug abuse. Bullying. Abusive parents. Dy...\n",
            "\n",
            " POST #2\n",
            "Title: Bfâ€™s mom covered my mouth while im having panic attacks. Is that abuse?\n",
            "Author: Psychological_Ant747\n",
            "Upvotes: 60 | Comments: 61\n",
            "Timestamp (UTC): 2025-12-02 12:09:17+00:00\n",
            "Body Preview: Hi everyone. I really need an outside perspective because I feel shaken, confused, and honestly scared. Iâ€™m staying with my family right now, trying t...\n",
            "\n",
            " POST #3\n",
            "Title: How did you friends and family react when you told them you were struggling?\n",
            "Author: Dorkas_ok\n",
            "Upvotes: 9 | Comments: 8\n",
            "Timestamp (UTC): 2025-12-02 18:59:33+00:00\n",
            "Body Preview: I want to open up to my family and friends about my struggles to try and get some professional help, but Iâ€™m scared. So I was wondering how your famil...\n",
            "\n",
            " POST #4\n",
            "Title: how do i stop caring so much about myself?\n",
            "Author: XKXKXKXXKXKXK\n",
            "Upvotes: 6 | Comments: 7\n",
            "Timestamp (UTC): 2025-12-02 18:06:30+00:00\n",
            "Body Preview: for the last few years iâ€™ve been stuck in this loop of hating everything about myself. i keep trying hobbies (crocheting, painting, random diy stuff) ...\n",
            "\n",
            " POST #5\n",
            "Title: I've ruined my life at the age of 19\n",
            "Author: Pu55ieDestroyer9000\n",
            "Upvotes: 70 | Comments: 33\n",
            "Timestamp (UTC): 2025-12-02 04:29:38+00:00\n",
            "Body Preview: I'm 19 in my second year of college and I already feel like my life is ruined. Completely worthless. I hate my life because of the things I've done. I...\n",
            "\n",
            " POST #6\n",
            "Title: My college roommateâ€™s porn addiction spiraled so badly he got kicked out of the dorms, and I still donâ€™t know how to process it\n",
            "Author: Levitating_Moose\n",
            "Upvotes: 290 | Comments: 40\n",
            "Timestamp (UTC): 2025-12-01 20:27:28+00:00\n",
            "Body Preview: Soâ€¦ this is something I never expected to write, but after everything that happened this semester, I need to get it out of my system.  I go to a prett...\n",
            "\n",
            " POST #7\n",
            "Title: I can't enjoy anything that's even remotely popular.\n",
            "Author: bigpoo9\n",
            "Upvotes: 3 | Comments: 1\n",
            "Timestamp (UTC): 2025-12-02 20:28:34+00:00\n",
            "Body Preview: I can't, but I'd want to enjoy things, like a normal human. Whenever something I do like gets brought up, I feel like I enjoy that thing less and less...\n",
            "\n",
            " POST #8\n",
            "Title: im thinking about giving up. i dont know who to reach out to\n",
            "Author: KittyMuffinx\n",
            "Upvotes: 3 | Comments: 3\n",
            "Timestamp (UTC): 2025-12-02 19:31:59+00:00\n",
            "Body Preview:  <18 f. i had to move to england 5 or so years ago from my home country due to political issues. ever since ive arrived i have felt the pressure to tr...\n",
            "\n",
            " POST #9\n",
            "Title: Point of life?\n",
            "Author: 2002VE68\n",
            "Upvotes: 7 | Comments: 3\n",
            "Timestamp (UTC): 2025-12-02 14:42:00+00:00\n",
            "Body Preview: Hi, I'm 15, struggling with mental health. My life feels very difficult at the moment and I actually just wanna know what I'm doing all this for?  I'm...\n",
            "\n",
            " POST #10\n",
            "Title: I feel unable to move\n",
            "Author: throoowwwaaw\n",
            "Upvotes: 2 | Comments: 1\n",
            "Timestamp (UTC): 2025-12-02 20:48:53+00:00\n",
            "Body Preview: Did the throwaway because I don't have anyone to talk to. I have the motivation to exercise and actually enjoy going to the gym, but I've been stuck i...\n",
            "\n",
            " POST #11\n",
            "Title: Honestly Iâ€™m proud of myself\n",
            "Author: ElephantGreedy5125\n",
            "Upvotes: 2 | Comments: 3\n",
            "Timestamp (UTC): 2025-12-02 20:17:40+00:00\n",
            "Body Preview: So since I was a kid Iâ€™ve struggled with seriously bad intrusive thoughts, my mum even said that when I was 5 I said the bad thoughts are telling me t...\n",
            "\n",
            " POST #12\n",
            "Title: surviving school with MDD\n",
            "Author: PerceptionMotor4328\n",
            "Upvotes: 2 | Comments: 1\n",
            "Timestamp (UTC): 2025-12-02 20:02:27+00:00\n",
            "Body Preview: I am a 16 (almost 17) year old girl in my junior year of hs. My entire life Iâ€™ve subconsciously known that something was a little off with me mentally...\n",
            "\n",
            " POST #13\n",
            "Title: Managing mental health without meds\n",
            "Author: W00zers\n",
            "Upvotes: 5 | Comments: 3\n",
            "Timestamp (UTC): 2025-12-02 13:48:00+00:00\n",
            "Body Preview: Is it even possible any tips? Iâ€™ve been struggling with severe depression and suicidal ideation for a while and itâ€™s only continued to get worse every...\n",
            "\n",
            " POST #14\n",
            "Title: looking for experience for providing support Sessions  â€“ Final Year Psychology Student, 20 F\n",
            "Author: Lazyie_pandaa\n",
            "Upvotes: 2 | Comments: 2\n",
            "Timestamp (UTC): 2025-12-02 18:39:46+00:00\n",
            "Body Preview: Hi! Iâ€™m a final-year psychology student looking to put my skills to use and gain practical experience. Iâ€™m still learning, but Iâ€™m genuinely passionat...\n",
            "\n",
            " POST #15\n",
            "Title: We need to kill evil\n",
            "Author: [deleted]\n",
            "Upvotes: 2 | Comments: 2\n",
            "Timestamp (UTC): 2025-12-02 18:38:21+00:00\n",
            "Body Preview: I've been thinking about how to kill evil and basically we will make a large chimera that is capable of hunting vbig bad wolves that are really danger...\n",
            "\n",
            " POST #16\n",
            "Title: Incident happened with mom, now I am remembering things.\n",
            "Author: PaulWithAPH\n",
            "Upvotes: 5 | Comments: 4\n",
            "Timestamp (UTC): 2025-12-02 14:49:52+00:00\n",
            "Body Preview: I am 43(M) if that matters.   About a month ago, I went to my parents' house to visit my mom. I knew dad was at work, but was just stopping by to say ...\n",
            "\n",
            " POST #17\n",
            "Title: I feel like life is too loud and I donâ€™t know how to cope anymore\n",
            "Author: humbleboy12\n",
            "Upvotes: 3 | Comments: 4\n",
            "Timestamp (UTC): 2025-12-02 15:50:43+00:00\n",
            "Body Preview: Everything has been overwhelming lately. My thoughts, my responsibilities, my emotionsâ€”everything feels louder than usual. Iâ€™m trying to keep it toget...\n",
            "\n",
            " POST #18\n",
            "Title: What are some easy simple task that can improve your mental health?\n",
            "Author: Ok-Reporter-8728\n",
            "Upvotes: 8 | Comments: 9\n",
            "Timestamp (UTC): 2025-12-02 10:01:13+00:00\n",
            "Body Preview: Sleeping 8 hours everyday \n",
            "\n",
            " POST #19\n",
            "Title: How do you support someone who refuses help and gets upset when things arenâ€™t exactly how they want?\n",
            "Author: According_Rooster357\n",
            "Upvotes: 1 | Comments: 0\n",
            "Timestamp (UTC): 2025-12-02 20:58:35+00:00\n",
            "Body Preview: Iâ€™m posting because Iâ€™m struggling emotionally with someone close to me, and Iâ€™m not sure how to handle it anymore.  This person deals with depression...\n",
            "\n",
            " POST #20\n",
            "Title: How should I go about this ?\n",
            "Author: Hell2009\n",
            "Upvotes: 3 | Comments: 0\n",
            "Timestamp (UTC): 2025-12-02 15:00:03+00:00\n",
            "Body Preview: I want to go to a psych ward or whatever but Idk how to talk with my dad about it (for context we are living together and hes the Only family I  have ...\n",
            " Collected 20 posts from r/mentalhealth\n",
            "\n",
            " Fetching 20 posts from r/AskReddit...\n",
            "\n",
            " POST #1\n",
            "Title: Who died believing themselves a failure, but was judged otherwise by history?\n",
            "Author: Bob_the_blacksmith\n",
            "Upvotes: 4581 | Comments: 1899\n",
            "Timestamp (UTC): 2025-12-02 11:36:10+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #2\n",
            "Title: How can Trump claim to be killing drug mules for national security but pardons Honduras former President, a convicted drug trafficker? Does everyone see the hypocrisy in that thought process?\n",
            "Author: TheTokist\n",
            "Upvotes: 1115 | Comments: 184\n",
            "Timestamp (UTC): 2025-12-02 18:20:24+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #3\n",
            "Title: What change is coming that people aren't prepared for at all?\n",
            "Author: nunash\n",
            "Upvotes: 1173 | Comments: 1261\n",
            "Timestamp (UTC): 2025-12-02 13:13:20+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #4\n",
            "Title: What is a \"poor person hack\" you picked up during a hard time that you still use today, even if you don't have to?\n",
            "Author: AmaraMehdi\n",
            "Upvotes: 11499 | Comments: 4489\n",
            "Timestamp (UTC): 2025-12-02 00:29:02+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #5\n",
            "Title: Whatâ€™s one truth about life that nobody warns you about?\n",
            "Author: fddssdhyyyyyyyyy\n",
            "Upvotes: 611 | Comments: 731\n",
            "Timestamp (UTC): 2025-12-02 14:46:12+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #6\n",
            "Title: How would you feel if the U.S. government made Election Day an official national holiday for everyone?\n",
            "Author: Mariam1S\n",
            "Upvotes: 425 | Comments: 305\n",
            "Timestamp (UTC): 2025-12-02 16:05:12+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #7\n",
            "Title: What is the biggest signal he/she wanted to have sex that you didnt get?\n",
            "Author: Aliyaowo\n",
            "Upvotes: 4398 | Comments: 1364\n",
            "Timestamp (UTC): 2025-12-02 03:26:29+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #8\n",
            "Title: What did you do this morning as soon as you woke up?\n",
            "Author: Outrageous-One-705\n",
            "Upvotes: 521 | Comments: 1843\n",
            "Timestamp (UTC): 2025-12-02 14:05:34+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #9\n",
            "Title: Redditors who have worked with celebrities, what don't we know about them?\n",
            "Author: 22m_spain\n",
            "Upvotes: 633 | Comments: 1193\n",
            "Timestamp (UTC): 2025-12-02 11:18:46+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #10\n",
            "Title: Whatâ€™s a rule you were taught as a kid that you later realized was completely made up?\n",
            "Author: SpiritualFig9994\n",
            "Upvotes: 268 | Comments: 587\n",
            "Timestamp (UTC): 2025-12-02 15:49:33+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #11\n",
            "Title: What's the worst song you ever heard?\n",
            "Author: Mission_Elk_329\n",
            "Upvotes: 210 | Comments: 1078\n",
            "Timestamp (UTC): 2025-12-02 16:04:48+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #12\n",
            "Title: How is the relationship between you and the person who took your virginity?\n",
            "Author: JAGAAAN-01\n",
            "Upvotes: 669 | Comments: 1377\n",
            "Timestamp (UTC): 2025-12-02 09:42:19+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #13\n",
            "Title: If you died and everyone said â€œThey died doing what they loved.â€  What was it that you were doing?\n",
            "Author: lukepaciocco\n",
            "Upvotes: 87 | Comments: 442\n",
            "Timestamp (UTC): 2025-12-02 19:55:20+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #14\n",
            "Title: What is a song that is really dirty, yet most people don't realize it?\n",
            "Author: _Volly\n",
            "Upvotes: 1885 | Comments: 2122\n",
            "Timestamp (UTC): 2025-12-02 02:16:01+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #15\n",
            "Title: What is a 'luxury' that has quietly become a necessity for you, and now you can't go back?\n",
            "Author: Top_Temperature6582\n",
            "Upvotes: 187 | Comments: 650\n",
            "Timestamp (UTC): 2025-12-02 14:32:08+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #16\n",
            "Title: Whatâ€™s the scariest WW2 fact or story that you know of?\n",
            "Author: Cool-Chipmunk-7559\n",
            "Upvotes: 683 | Comments: 846\n",
            "Timestamp (UTC): 2025-12-02 05:35:30+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #17\n",
            "Title: If your life was a video game, what 'loading screen tip' would you see right now?\n",
            "Author: emotionprocessor\n",
            "Upvotes: 54 | Comments: 106\n",
            "Timestamp (UTC): 2025-12-02 18:39:09+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #18\n",
            "Title: What industry is so powerful that we don't question their control of us?\n",
            "Author: _marimbae\n",
            "Upvotes: 69 | Comments: 158\n",
            "Timestamp (UTC): 2025-12-02 17:03:28+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #19\n",
            "Title: Whatâ€™s a smell you instantly associate with your childhood?\n",
            "Author: Manojnaidu13\n",
            "Upvotes: 46 | Comments: 192\n",
            "Timestamp (UTC): 2025-12-02 18:43:33+00:00\n",
            "Body Preview: \n",
            "\n",
            " POST #20\n",
            "Title: Whatâ€™s one â€œbroke habitâ€ youâ€™re keeping for life, even if you ended up filthy rich?\n",
            "Author: Remote-Lawyer-2462\n",
            "Upvotes: 35 | Comments: 133\n",
            "Timestamp (UTC): 2025-12-02 20:29:01+00:00\n",
            "Body Preview: \n",
            " Collected 20 posts from r/AskReddit\n",
            "\n",
            "======================================================================\n",
            " Raw Reddit Data Preview (First 10 rows) \n",
            "======================================================================\n",
            "subreddit                                                                                                                                                                                           title body             author  upvotes  num_comments                 timestamp\n",
            "AskReddit                                                                              What is a \"poor person hack\" you picked up during a hard time that you still use today, even if you don't have to?              AmaraMehdi    11499          4489 2025-12-02 00:29:02+00:00\n",
            "AskReddit                                                                                                                   Who died believing themselves a failure, but was judged otherwise by history?      Bob_the_blacksmith     4581          1899 2025-12-02 11:36:10+00:00\n",
            "AskReddit                                                                                                                        What is the biggest signal he/she wanted to have sex that you didnt get?                Aliyaowo     4398          1364 2025-12-02 03:26:29+00:00\n",
            "AskReddit                                                                                                                          What is a song that is really dirty, yet most people don't realize it?                  _Volly     1885          2122 2025-12-02 02:16:01+00:00\n",
            "AskReddit                                                                                                                                   What change is coming that people aren't prepared for at all?                  nunash     1173          1261 2025-12-02 13:13:20+00:00\n",
            "AskReddit How can Trump claim to be killing drug mules for national security but pardons Honduras former President, a convicted drug trafficker? Does everyone see the hypocrisy in that thought process?               TheTokist     1115           184 2025-12-02 18:20:24+00:00\n",
            "AskReddit                                                                                                                                         Whatâ€™s the scariest WW2 fact or story that you know of?      Cool-Chipmunk-7559      683           846 2025-12-02 05:35:30+00:00\n",
            "AskReddit                                                                                                                     How is the relationship between you and the person who took your virginity?              JAGAAAN-01      669          1377 2025-12-02 09:42:19+00:00\n",
            "AskReddit                                                                                                                      Redditors who have worked with celebrities, what don't we know about them?               22m_spain      633          1193 2025-12-02 11:18:46+00:00\n",
            "AskReddit                                                                                                                                        Whatâ€™s one truth about life that nobody warns you about?        fddssdhyyyyyyyyy      611           731 2025-12-02 14:46:12+00:00\n",
            "\n",
            " Saved raw_reddit_data.csv successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Text Cleaning & Preprocessing  \n",
        "\n",
        "\n",
        "This section explains the preprocessing workflow applied to clean and prepare raw Reddit text data for NLP tasks like classification and sentiment analysis.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Œ **Overview**\n",
        "Reddit posts often contain noise such as URLs, punctuation, numbers, and unnecessary words. To improve text quality and make it useful for NLP models, a structured preprocessing pipeline was applied.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”„ **Preprocessing Steps**\n",
        "\n",
        "### **1ï¸âƒ£ Lowercasing**\n",
        "All text is converted to lowercase so words like \"Food\" and \"food\" are treated the same.\n",
        "\n",
        "### **2ï¸âƒ£ Removing Noise**\n",
        "Using Python's `re` library, the following elements are removed:\n",
        "- URLs  \n",
        "- Mentions (`@username`)  \n",
        "- Hashtags (`#topic`)  \n",
        "- Punctuation  \n",
        "- Numbers  \n",
        "- Special characters  \n",
        "\n",
        "### **3ï¸âƒ£ Tokenization**\n",
        "Each sentence is split into individual words using **NLTKâ€™s tokenizer**, preparing it for stopword removal and analysis.\n",
        "\n",
        "### **4ï¸âƒ£ Stopword Removal**\n",
        "Stopwords are removed using:\n",
        "- **NLTK English stopword list**\n",
        "- **Custom Reddit-specific stopwords** such as:  \n",
        "  `like, want, think, people, get, good, many, even`\n",
        "\n",
        "### **5ï¸âƒ£ Whitespace Normalization**\n",
        "Extra spaces, multiple spaces, and line breaks are cleaned for consistent formatting.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“˜ **Libraries Used**\n",
        "- **NLTK** â€“ tokenization, stopword removal  \n",
        "- **re** â€“ regex-based text cleaning  \n",
        "- **pandas** â€“ dataset handling & creation of new columns  \n",
        "- **tabulate** â€“ printing before/after comparison tables  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“„ **New Columns Generated**\n",
        "| Column Name | Description |\n",
        "|-------------|-------------|\n",
        "| **cleaned_title** | Cleaned version of the post title |\n",
        "| **cleaned_body** | Cleaned version of the post body |\n",
        "| **full_text** | Combined original title and body |\n",
        "| **cleaned_full_text** | Fully cleaned version of full_text |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¾ **Final Output**\n",
        "The processed dataset is saved as:\n",
        "preprocessed_reddit_data.csv\n"
      ],
      "metadata": {
        "id": "J72gcb9zAqog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from tabulate import tabulate\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\" TEXT CLEANING & PREPROCESSING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\" Downloading NLTK resources...\")\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "print(\" NLTK resources ready\")\n",
        "\n",
        "print(\"\\n Loading data from raw_reddit_data.csv...\")\n",
        "df = pd.read_csv('raw_reddit_data.csv')\n",
        "print(f\" Loaded {len(df)} posts\")\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "reddit_stopwords = [\n",
        "    'like', 'get', 'would', 'could', 'also', 'really', 'one', 'much', 'many',\n",
        "    'even', 'still', 'maybe', 'think', 'know', 'said', 'people', 'thing', 'things',\n",
        "    'go', 'see', 'want', 'need', 'make', 'take', 'good'\n",
        "]\n",
        "stop_words.update(reddit_stopwords)\n",
        "\n",
        "def preprocess_text(text, remove_stopwords=True, remove_numbers=True):\n",
        "    if not isinstance(text, str) or pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    text = text.lower().strip()  # lowercase and trim\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # remove URLs\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)  # remove mentions & hashtags\n",
        "    text = re.sub(r'[^a-zA-Z\\s]' if remove_numbers else r'[^\\w\\s]', '', text)  # remove punctuation/numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    if remove_stopwords:\n",
        "        tokens = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "print(\"\\n Applying preprocessing to posts...\")\n",
        "df['cleaned_title'] = df['title'].apply(preprocess_text)\n",
        "df['cleaned_body'] = df['body'].apply(lambda x: preprocess_text(x) if pd.notna(x) else \"\")\n",
        "df['full_text'] = df['title'] + ' ' + df['body'].fillna('')\n",
        "df['cleaned_full_text'] = df['full_text'].apply(preprocess_text)\n",
        "\n",
        "print(\" Preprocessing complete!\")\n",
        "print(f\"   â€¢ Original columns: {len([c for c in df.columns if 'cleaned' not in c])}\")\n",
        "print(f\"   â€¢ New columns: cleaned_title, cleaned_body, full_text, cleaned_full_text\")\n",
        "\n",
        "sample_indices = []\n",
        "for sub in df['subreddit'].unique():\n",
        "    sub_df = df[df['subreddit'] == sub]\n",
        "    if len(sub_df) > 0:\n",
        "        sample_indices.append(sub_df.index[0])\n",
        "\n",
        "# Ensure exactly 5 samples\n",
        "if len(sample_indices) < 5:\n",
        "    remaining = df.index.difference(sample_indices)[:5 - len(sample_indices)]\n",
        "    sample_indices.extend(remaining)\n",
        "sample_indices = sample_indices[:5]\n",
        "\n",
        "truncate = lambda text, n: text[:n] + (\"...\" if len(text) > n else \"\")\n",
        "\n",
        "# Prepare comparison data\n",
        "comparison_data = []\n",
        "for idx in sample_indices:\n",
        "    original_title = df.loc[idx, 'title']\n",
        "    cleaned_title = df.loc[idx, 'cleaned_title']\n",
        "    body_text = df.loc[idx, 'body']\n",
        "    original_body = \"\" if pd.isna(body_text) else str(body_text)\n",
        "    cleaned_body = df.loc[idx, 'cleaned_body']\n",
        "    subreddit = df.loc[idx, 'subreddit']\n",
        "\n",
        "    orig_words = len(original_title.split()) + len(original_body.split())\n",
        "    clean_words = len(cleaned_title.split()) + len(cleaned_body.split())\n",
        "    reduction = orig_words - clean_words\n",
        "    reduction_pct = (reduction / orig_words * 100) if orig_words > 0 else 0\n",
        "\n",
        "    comparison_data.append({\n",
        "        '#': idx + 1,\n",
        "        'Subreddit': f\"r/{subreddit}\",\n",
        "        'Original Title': truncate(original_title, 60),\n",
        "        'Cleaned Title': truncate(cleaned_title, 60),\n",
        "        'Original Body': truncate(original_body, 80),\n",
        "        'Cleaned Body': truncate(cleaned_body, 80),\n",
        "        'Word Count': f\"{orig_words} â†’ {clean_words}\",\n",
        "        'Reduction': f\"{reduction} ({reduction_pct:.1f}%)\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n BEFORE/AFTER COMPARISON (5 Samples)\")\n",
        "print(\"=\"*120)\n",
        "print(tabulate(comparison_df, headers='keys', tablefmt='fancy_grid', showindex=False, stralign='left'))\n",
        "print(\"=\"*120)\n",
        "\n",
        "print(\"\\n BODY TEXT COMPARISON:\")\n",
        "for _, row in comparison_df.iterrows():\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"Sample {row['#']} ({row['Subreddit']}) | Words: {row['Word Count']} | Reduction: {row['Reduction']}\")\n",
        "    print(f\"Original: {row['Original Body']}\")\n",
        "    print(f\"Cleaned:  {row['Cleaned Body']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" PREPROCESSING STEPS DEMONSTRATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "sample_idx = sample_indices[0]\n",
        "sample_text = df.loc[sample_idx, 'title']\n",
        "print(f\"\\n Sample Text: '{sample_text}'\")\n",
        "\n",
        "step_lower = sample_text.lower()\n",
        "step_no_url = re.sub(r'http\\S+|www\\S+|https\\S+', '', step_lower)\n",
        "step_no_punct = re.sub(r'[^a-zA-Z\\s]', '', step_no_url)\n",
        "tokens = word_tokenize(step_no_punct)\n",
        "tokens_no_stop = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "steps = [\n",
        "    (\"1. Lowercase\", step_lower),\n",
        "    (\"2. Remove URLs\", step_no_url),\n",
        "    (\"3. Remove punctuation\", step_no_punct),\n",
        "    (\"4. Tokenize\", tokens),\n",
        "    (\"5. Remove stopwords\", tokens_no_stop),\n",
        "    (\"6. Final cleaned\", preprocess_text(sample_text))\n",
        "]\n",
        "\n",
        "for name, result in steps:\n",
        "    if isinstance(result, list):\n",
        "        print(f\"{name}: {result[:10]}...\")\n",
        "    else:\n",
        "        print(f\"{name}: '{result[:80]}'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" SAVING PROCESSED DATA\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "output_file = \"preprocessed_reddit_data.csv\"\n",
        "df.to_csv(output_file, index=False, encoding='utf-8')\n",
        "print(f\" Saved to: {output_file}\")\n",
        "print(f\" Total posts: {len(df)}\")\n",
        "print(f\" File size: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5GBE-EDwKLQ",
        "outputId": "15c680e9-0c81-45f3-ce2c-6a7b7bf620a1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " TEXT CLEANING & PREPROCESSING\n",
            "======================================================================\n",
            " Downloading NLTK resources...\n",
            " NLTK resources ready\n",
            "\n",
            " Loading data from raw_reddit_data.csv...\n",
            " Loaded 60 posts\n",
            "\n",
            " Applying preprocessing to posts...\n",
            " Preprocessing complete!\n",
            "   â€¢ Original columns: 8\n",
            "   â€¢ New columns: cleaned_title, cleaned_body, full_text, cleaned_full_text\n",
            "\n",
            " BEFORE/AFTER COMPARISON (5 Samples)\n",
            "========================================================================================================================\n",
            "â•’â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
            "â”‚   # â”‚ Subreddit      â”‚ Original Title                                                  â”‚ Cleaned Title                                                   â”‚ Original Body                                                                       â”‚ Cleaned Body                                                                        â”‚ Word Count   â”‚ Reduction   â”‚\n",
            "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚   1 â”‚ r/AskReddit    â”‚ What is a \"poor person hack\" you picked up during a hard tim... â”‚ poor person hack picked hard time use today dont                â”‚                                                                                     â”‚                                                                                     â”‚ 24 â†’ 9       â”‚ 15 (62.5%)  â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  21 â”‚ r/mentalhealth â”‚ My college roommateâ€™s porn addiction spiraled so badly he go... â”‚ college roommates porn addiction spiraled badly got kicked d... â”‚ Soâ€¦ this is something I never expected to write, but after everything that happe... â”‚ something never expected write everything happened semester system pretty normal... â”‚ 587 â†’ 290    â”‚ 297 (50.6%) â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚  41 â”‚ r/technology   â”‚ Rockstar co-founder compares AI to 'mad cow disease,' and sa... â”‚ rockstar cofounder compares ai mad cow disease says execs pu... â”‚                                                                                     â”‚                                                                                     â”‚ 17 â†’ 13      â”‚ 4 (23.5%)   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚   2 â”‚ r/AskReddit    â”‚ Who died believing themselves a failure, but was judged othe... â”‚ died believing failure judged otherwise history                 â”‚                                                                                     â”‚                                                                                     â”‚ 12 â†’ 6       â”‚ 6 (50.0%)   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚   3 â”‚ r/AskReddit    â”‚ What is the biggest signal he/she wanted to have sex that yo... â”‚ biggest signal heshe wanted sex didnt                           â”‚                                                                                     â”‚                                                                                     â”‚ 14 â†’ 6       â”‚ 8 (57.1%)   â”‚\n",
            "â•˜â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n",
            "========================================================================================================================\n",
            "\n",
            " BODY TEXT COMPARISON:\n",
            "\n",
            "====================================================================================================\n",
            "Sample 1 (r/AskReddit) | Words: 24 â†’ 9 | Reduction: 15 (62.5%)\n",
            "Original: \n",
            "Cleaned:  \n",
            "\n",
            "====================================================================================================\n",
            "Sample 21 (r/mentalhealth) | Words: 587 â†’ 290 | Reduction: 297 (50.6%)\n",
            "Original: Soâ€¦ this is something I never expected to write, but after everything that happe...\n",
            "Cleaned:  something never expected write everything happened semester system pretty normal...\n",
            "\n",
            "====================================================================================================\n",
            "Sample 41 (r/technology) | Words: 17 â†’ 13 | Reduction: 4 (23.5%)\n",
            "Original: \n",
            "Cleaned:  \n",
            "\n",
            "====================================================================================================\n",
            "Sample 2 (r/AskReddit) | Words: 12 â†’ 6 | Reduction: 6 (50.0%)\n",
            "Original: \n",
            "Cleaned:  \n",
            "\n",
            "====================================================================================================\n",
            "Sample 3 (r/AskReddit) | Words: 14 â†’ 6 | Reduction: 8 (57.1%)\n",
            "Original: \n",
            "Cleaned:  \n",
            "\n",
            "======================================================================\n",
            " PREPROCESSING STEPS DEMONSTRATION\n",
            "======================================================================\n",
            "\n",
            " Sample Text: 'What is a \"poor person hack\" you picked up during a hard time that you still use today, even if you don't have to?'\n",
            "1. Lowercase: 'what is a \"poor person hack\" you picked up during a hard time that you still use'\n",
            "2. Remove URLs: 'what is a \"poor person hack\" you picked up during a hard time that you still use'\n",
            "3. Remove punctuation: 'what is a poor person hack you picked up during a hard time that you still use t'\n",
            "4. Tokenize: ['what', 'is', 'a', 'poor', 'person', 'hack', 'you', 'picked', 'up', 'during']...\n",
            "5. Remove stopwords: ['poor', 'person', 'hack', 'picked', 'hard', 'time', 'use', 'today', 'dont']...\n",
            "6. Final cleaned: 'poor person hack picked hard time use today dont'\n",
            "\n",
            "======================================================================\n",
            " SAVING PROCESSED DATA\n",
            "======================================================================\n",
            " Saved to: preprocessed_reddit_data.csv\n",
            " Total posts: 60\n",
            " File size: 161.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Post Classification\n",
        "\n",
        "- Load preprocessed Reddit data\n",
        "- Perform sentiment analysis using **VADER** and **TextBlob**\n",
        "- Combine results to get a final sentiment\n",
        "- Classify posts into topics based on keywords\n",
        "\n",
        "---\n",
        "\n",
        "## Sentiment Analysis\n",
        "\n",
        "Sentiments analyzed:\n",
        "\n",
        "- **Positive** ğŸ˜Š\n",
        "- **Neutral** ğŸ˜\n",
        "- **Negative** ğŸ˜”"
      ],
      "metadata": {
        "id": "swUeAg8ILAxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from textblob import TextBlob\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\" PART 3: POST CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('preprocessed_reddit_data.csv')\n",
        "print(f\" Loaded {len(df)} preprocessed posts\")\n",
        "\n",
        "# Initialize analyzer\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "def analyze_sentiment_vader(text):\n",
        "    \"\"\"Analyze sentiment using VADER\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return {'sentiment': 'neutral', 'compound': 0}\n",
        "\n",
        "    scores = vader.polarity_scores(text)\n",
        "    compound = scores['compound']\n",
        "\n",
        "    if compound >= 0.05:\n",
        "        sentiment = 'positive'\n",
        "    elif compound <= -0.05:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'neutral'\n",
        "\n",
        "    return {'sentiment': sentiment, 'compound': compound}\n",
        "\n",
        "def analyze_sentiment_textblob(text):\n",
        "    \"\"\"Analyze sentiment using TextBlob\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return {'sentiment': 'neutral', 'polarity': 0}\n",
        "\n",
        "    blob = TextBlob(text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "\n",
        "    if polarity > 0:\n",
        "        sentiment = 'positive'\n",
        "    elif polarity < 0:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'neutral'\n",
        "\n",
        "    return {'sentiment': sentiment, 'polarity': polarity}\n",
        "\n",
        "def get_final_sentiment(text):\n",
        "    \"\"\"Combine VADER and TextBlob results\"\"\"\n",
        "    vader_result = analyze_sentiment_vader(text)\n",
        "    textblob_result = analyze_sentiment_textblob(text)\n",
        "\n",
        "    # If both agree, use that\n",
        "    if vader_result['sentiment'] == textblob_result['sentiment']:\n",
        "        return vader_result['sentiment']\n",
        "\n",
        "    # If one is neutral, prefer the non-neutral\n",
        "    if vader_result['sentiment'] == 'neutral':\n",
        "        return textblob_result['sentiment']\n",
        "    if textblob_result['sentiment'] == 'neutral':\n",
        "        return vader_result['sentiment']\n",
        "\n",
        "    # Otherwise use VADER (better for social media)\n",
        "    return vader_result['sentiment']\n",
        "\n",
        "print(\" Performing sentiment analysis...\")\n",
        "\n",
        "# Get individual model results\n",
        "df['vader_sentiment'] = df['cleaned_full_text'].apply(lambda x: analyze_sentiment_vader(x)['sentiment'])\n",
        "df['vader_compound'] = df['cleaned_full_text'].apply(lambda x: analyze_sentiment_vader(x)['compound'])\n",
        "df['textblob_sentiment'] = df['cleaned_full_text'].apply(lambda x: analyze_sentiment_textblob(x)['sentiment'])\n",
        "df['textblob_polarity'] = df['cleaned_full_text'].apply(lambda x: analyze_sentiment_textblob(x)['polarity'])\n",
        "\n",
        "# Get final combined sentiment\n",
        "df['final_sentiment'] = df['cleaned_full_text'].apply(get_final_sentiment)\n",
        "\n",
        "print(\" Sentiment analysis complete!\")\n",
        "\n",
        "print(\" Performing topic classification...\")\n",
        "\n",
        "topic_keywords = {\n",
        "    'technology': ['tech', 'ai', 'software', 'computer', 'app', 'internet', 'digital',\n",
        "                   'data', 'code', 'programming', 'machine', 'algorithm', 'cyber',\n",
        "                   'security', 'cloud', 'crypto', 'phone', 'website', 'windows', 'android'],\n",
        "    'mental_health': ['mental', 'therapy', 'anxiety', 'stress', 'depression', 'health',\n",
        "                     'wellness', 'mindfulness', 'psychology', 'counseling', 'emotion',\n",
        "                     'mind', 'happy', 'sad', 'angry', 'treatment', 'support', 'trauma',\n",
        "                     'ptsd', 'disorder'],\n",
        "    'education': ['school', 'college', 'university', 'study', 'learn', 'education',\n",
        "                 'course', 'student', 'teacher', 'knowledge', 'skill', 'degree',\n",
        "                 'exam', 'homework', 'class', 'professor', 'tuition', 'campus'],\n",
        "    'entertainment': ['movie', 'music', 'game', 'tv', 'show', 'entertainment', 'fun',\n",
        "                     'comedy', 'drama', 'film', 'song', 'artist', 'actor', 'celebrity',\n",
        "                     'series', 'episode', 'season', 'netflix', 'youtube', 'spotify'],\n",
        "    'politics': ['government', 'politic', 'election', 'vote', 'law', 'policy',\n",
        "                'democrat', 'republican', 'congress', 'senate', 'president',\n",
        "                'bill', 'senator', 'representative', 'supreme', 'court']\n",
        "}\n",
        "\n",
        "def classify_topic(text):\n",
        "    \"\"\"Classify text into topics based on keyword matching\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return 'other'\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    scores = {}\n",
        "\n",
        "    for topic, keywords in topic_keywords.items():\n",
        "        score = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "        scores[topic] = score\n",
        "\n",
        "    if max(scores.values()) > 0:\n",
        "        return max(scores, key=scores.get)\n",
        "    else:\n",
        "        return 'other'\n",
        "\n",
        "# Apply topic classification\n",
        "df['primary_topic'] = df['cleaned_full_text'].apply(classify_topic)\n",
        "\n",
        "print(\" Topic classification complete!\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" CONFUSION MATRIX & MODEL AGREEMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Calculate accuracy and confusion matrix\n",
        "accuracy = accuracy_score(df['vader_sentiment'], df['textblob_sentiment'])\n",
        "cm = confusion_matrix(df['vader_sentiment'], df['textblob_sentiment'],\n",
        "                      labels=['negative', 'neutral', 'positive'])\n",
        "\n",
        "print(f\"\\n Model Agreement Analysis:\")\n",
        "print(f\"   â€¢ VADER vs TextBlob Accuracy: {accuracy:.2%}\")\n",
        "print(f\"   â€¢ Total Posts: {len(df)}\")\n",
        "print(f\"   â€¢ Agreements: {int(accuracy * len(df))}\")\n",
        "print(f\"   â€¢ Disagreements: {int((1 - accuracy) * len(df))}\")\n",
        "\n",
        "print(\"\\n Confusion Matrix (VADER vs TextBlob):\")\n",
        "print(\" \" * 15 + \"TextBlob Predictions\")\n",
        "print(\" \" * 15 + \"-\" * 40)\n",
        "print(\" \" * 10 + \"Negative   Neutral   Positive\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "labels = ['negative', 'neutral', 'positive']\n",
        "for i, true_label in enumerate(labels):\n",
        "    row = f\"VADER {true_label:<7}\"\n",
        "    for j in range(3):\n",
        "        row += f\"{cm[i][j]:^10}\"\n",
        "    print(row)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" CLASSIFICATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Sentiment Distribution\n",
        "print(\"\\n SENTIMENT DISTRIBUTION:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "sentiment_counts = df['final_sentiment'].value_counts()\n",
        "total = len(df)\n",
        "\n",
        "print(f\"{'Sentiment':<10} {'Count':<8} {'Percentage':<12} {'Emoji':<5}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "emoji_map = {'positive': 'ğŸ˜Š', 'neutral': 'ğŸ˜', 'negative': 'ğŸ˜”'}\n",
        "for sentiment, count in sentiment_counts.items():\n",
        "    percentage = (count / total) * 100\n",
        "    emoji = emoji_map.get(sentiment, 'â“')\n",
        "    print(f\"{sentiment:<10} {count:<8} {percentage:<11.1f}% {emoji:<5}\")\n",
        "\n",
        "# Topic Distribution\n",
        "print(\"\\n TOPIC DISTRIBUTION:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "topic_counts = df['primary_topic'].value_counts()\n",
        "\n",
        "print(f\"{'Topic':<15} {'Count':<8} {'Percentage':<12}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for topic, count in topic_counts.items():\n",
        "    percentage = (count / total) * 100\n",
        "    print(f\"{topic:<15} {count:<8} {percentage:<11.1f}%\")\n",
        "\n",
        "# Sentiment by Subreddit\n",
        "print(\"\\n SENTIMENT BY SUBREDDIT:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"{'Subreddit':<15} {'Positive':<10} {'Neutral':<10} {'Negative':<10} {'Dominant':<10}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for subreddit in df['subreddit'].unique():\n",
        "    sub_df = df[df['subreddit'] == subreddit]\n",
        "    positive = len(sub_df[sub_df['final_sentiment'] == 'positive'])\n",
        "    neutral = len(sub_df[sub_df['final_sentiment'] == 'neutral'])\n",
        "    negative = len(sub_df[sub_df['final_sentiment'] == 'negative'])\n",
        "    dominant = sub_df['final_sentiment'].value_counts().index[0]\n",
        "\n",
        "    print(f\"r/{subreddit:<13} {positive:<10} {neutral:<10} {negative:<10} {dominant:<10}\")\n",
        "\n",
        "# Topic by Subreddit\n",
        "print(\"\\n TOPIC BY SUBREDDIT:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for subreddit in df['subreddit'].unique():\n",
        "    sub_df = df[df['subreddit'] == subreddit]\n",
        "    dominant_topic = sub_df['primary_topic'].value_counts().index[0]\n",
        "    print(f\"r/{subreddit}: Most common topic = {dominant_topic}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" SAMPLE CLASSIFIED POSTS \")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Select diverse samples\n",
        "samples = []\n",
        "for sentiment in ['positive', 'neutral', 'negative']:\n",
        "    sentiment_samples = df[df['final_sentiment'] == sentiment].head(2).index.tolist()\n",
        "    samples.extend(sentiment_samples)\n",
        "\n",
        "samples = samples[:5]\n",
        "\n",
        "print(\"\\n Sample Classification Results:\")\n",
        "print(\"-\" * 120)\n",
        "\n",
        "for idx in samples:\n",
        "    post = df.loc[idx]\n",
        "    print(f\"\\n{'='*120}\")\n",
        "    print(f\" POST #{idx + 1} | r/{post['subreddit']}\")\n",
        "    print(f\"{'='*120}\")\n",
        "    print(f\"Title: {post['title'][:80]}...\")\n",
        "    print(f\"Cleaned: {post['cleaned_title'][:100]}...\")\n",
        "    print(f\"\\n Sentiment: {post['final_sentiment']} (VADER: {post['vader_sentiment']}, TextBlob: {post['textblob_sentiment']})\")\n",
        "    print(f\" Topic: {post['primary_topic']}\")\n",
        "    print(f\" VADER Score: {post['vader_compound']:.3f} | TextBlob Polarity: {post['textblob_polarity']:.3f}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" SAVING FINAL CLASSIFIED DATASET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Reorder columns for better readability\n",
        "column_order = [\n",
        "    'subreddit', 'title', 'cleaned_title', 'body', 'cleaned_body',\n",
        "    'author', 'upvotes', 'num_comments', 'timestamp',\n",
        "    'vader_sentiment', 'vader_compound',\n",
        "    'textblob_sentiment', 'textblob_polarity',\n",
        "    'final_sentiment', 'primary_topic',\n",
        "    'full_text', 'cleaned_full_text'\n",
        "]\n",
        "\n",
        "# Select only existing columns\n",
        "existing_columns = [col for col in column_order if col in df.columns]\n",
        "remaining_columns = [col for col in df.columns if col not in existing_columns]\n",
        "final_columns = existing_columns + remaining_columns\n",
        "\n",
        "df_final = df[final_columns]\n",
        "\n",
        "# Save to CSV\n",
        "output_file = \"classified_reddit_data.csv\"\n",
        "df_final.to_csv(output_file, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\" Final dataset saved to: {output_file}\")\n",
        "print(f\" File contains: {len(df_final)} posts\")\n",
        "print(f\" Total columns: {len(df_final.columns)}\")\n",
        "print(f\" File size: {df_final.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
        "\n",
        "print(f\"\\n KEY CLASSIFICATION COLUMNS ADDED:\")\n",
        "classification_cols = ['vader_sentiment', 'textblob_sentiment', 'final_sentiment', 'primary_topic']\n",
        "for col in classification_cols:\n",
        "    print(f\"   â€¢ {col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP-MEkt1_4HM",
        "outputId": "6ab84a6c-c590-4566-d77c-5d417c907d63"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " PART 3: POST CLASSIFICATION\n",
            "======================================================================\n",
            " Loaded 60 preprocessed posts\n",
            " Performing sentiment analysis...\n",
            " Sentiment analysis complete!\n",
            " Performing topic classification...\n",
            " Topic classification complete!\n",
            "\n",
            "======================================================================\n",
            " CONFUSION MATRIX & MODEL AGREEMENT\n",
            "======================================================================\n",
            "\n",
            " Model Agreement Analysis:\n",
            "   â€¢ VADER vs TextBlob Accuracy: 66.67%\n",
            "   â€¢ Total Posts: 60\n",
            "   â€¢ Agreements: 40\n",
            "   â€¢ Disagreements: 20\n",
            "\n",
            " Confusion Matrix (VADER vs TextBlob):\n",
            "               TextBlob Predictions\n",
            "               ----------------------------------------\n",
            "          Negative   Neutral   Positive\n",
            "---------------------------------------------\n",
            "VADER negative    18        9         3     \n",
            "VADER neutral    2         12        1     \n",
            "VADER positive    2         3         10    \n",
            "\n",
            "======================================================================\n",
            " CLASSIFICATION RESULTS\n",
            "======================================================================\n",
            "\n",
            " SENTIMENT DISTRIBUTION:\n",
            "----------------------------------------\n",
            "Sentiment  Count    Percentage   Emoji\n",
            "----------------------------------------\n",
            "negative   32       53.3       % ğŸ˜”    \n",
            "positive   16       26.7       % ğŸ˜Š    \n",
            "neutral    12       20.0       % ğŸ˜    \n",
            "\n",
            " TOPIC DISTRIBUTION:\n",
            "----------------------------------------\n",
            "Topic           Count    Percentage  \n",
            "----------------------------------------\n",
            "other           20       33.3       %\n",
            "technology      15       25.0       %\n",
            "mental_health   14       23.3       %\n",
            "entertainment   6        10.0       %\n",
            "politics        3        5.0        %\n",
            "education       2        3.3        %\n",
            "\n",
            " SENTIMENT BY SUBREDDIT:\n",
            "--------------------------------------------------\n",
            "Subreddit       Positive   Neutral    Negative   Dominant  \n",
            "--------------------------------------------------\n",
            "r/AskReddit     5          7          8          negative  \n",
            "r/mentalhealth  8          0          12         negative  \n",
            "r/technology    3          5          12         negative  \n",
            "\n",
            " TOPIC BY SUBREDDIT:\n",
            "----------------------------------------\n",
            "r/AskReddit: Most common topic = other\n",
            "r/mentalhealth: Most common topic = mental_health\n",
            "r/technology: Most common topic = technology\n",
            "\n",
            "======================================================================\n",
            " SAMPLE CLASSIFIED POSTS \n",
            "======================================================================\n",
            "\n",
            " Sample Classification Results:\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "========================================================================================================================\n",
            " POST #10 | r/AskReddit\n",
            "========================================================================================================================\n",
            "Title: Whatâ€™s one truth about life that nobody warns you about?...\n",
            "Cleaned: whats truth life nobody warns...\n",
            "\n",
            " Sentiment: positive (VADER: positive, TextBlob: neutral)\n",
            " Topic: other\n",
            " VADER Score: 0.226 | TextBlob Polarity: 0.000\n",
            "\n",
            "========================================================================================================================\n",
            " POST #12 | r/AskReddit\n",
            "========================================================================================================================\n",
            "Title: How would you feel if the U.S. government made Election Day an official national...\n",
            "Cleaned: feel us government made election day official national holiday everyone...\n",
            "\n",
            " Sentiment: positive (VADER: positive, TextBlob: neutral)\n",
            " Topic: politics\n",
            " VADER Score: 0.402 | TextBlob Polarity: 0.000\n",
            "\n",
            "========================================================================================================================\n",
            " POST #3 | r/AskReddit\n",
            "========================================================================================================================\n",
            "Title: What is the biggest signal he/she wanted to have sex that you didnt get?...\n",
            "Cleaned: biggest signal heshe wanted sex didnt...\n",
            "\n",
            " Sentiment: neutral (VADER: neutral, TextBlob: neutral)\n",
            " Topic: other\n",
            " VADER Score: 0.000 | TextBlob Polarity: 0.000\n",
            "\n",
            "========================================================================================================================\n",
            " POST #7 | r/AskReddit\n",
            "========================================================================================================================\n",
            "Title: Whatâ€™s the scariest WW2 fact or story that you know of?...\n",
            "Cleaned: whats scariest ww fact story...\n",
            "\n",
            " Sentiment: neutral (VADER: neutral, TextBlob: neutral)\n",
            " Topic: other\n",
            " VADER Score: 0.000 | TextBlob Polarity: 0.000\n",
            "\n",
            "========================================================================================================================\n",
            " POST #1 | r/AskReddit\n",
            "========================================================================================================================\n",
            "Title: What is a \"poor person hack\" you picked up during a hard time that you still use...\n",
            "Cleaned: poor person hack picked hard time use today dont...\n",
            "\n",
            " Sentiment: negative (VADER: negative, TextBlob: negative)\n",
            " Topic: other\n",
            " VADER Score: -0.542 | TextBlob Polarity: -0.346\n",
            "\n",
            "======================================================================\n",
            " SAVING FINAL CLASSIFIED DATASET\n",
            "======================================================================\n",
            " Final dataset saved to: classified_reddit_data.csv\n",
            " File contains: 60 posts\n",
            " Total columns: 17\n",
            " File size: 175.4 KB\n",
            "\n",
            " KEY CLASSIFICATION COLUMNS ADDED:\n",
            "   â€¢ vader_sentiment\n",
            "   â€¢ textblob_sentiment\n",
            "   â€¢ final_sentiment\n",
            "   â€¢ primary_topic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apscheduler\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCz6mhNfweDO",
        "outputId": "42c8d56c-12e9-4638-fdd1-2088aede737a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apscheduler\n",
            "  Downloading apscheduler-3.11.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: tzlocal>=3.0 in /usr/local/lib/python3.12/dist-packages (from apscheduler) (5.3.1)\n",
            "Downloading apscheduler-3.11.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apscheduler\n",
            "Successfully installed apscheduler-3.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reddit Real-Time Data Scraper\n",
        "\n",
        "This project contains a Python script to **collect Reddit posts in real-time** using **PRAW** and save them for analysis. The script runs continuously with a **scheduler** to fetch posts at regular intervals.\n",
        "\n",
        "---\n",
        "\n",
        "## Features\n",
        "\n",
        "- Connects to Reddit using **API credentials** from `.env`  \n",
        "- Fetches posts from multiple **subreddits** (e.g., `technology`, `mentalhealth`, `AskReddit`)  \n",
        "- Collects key post information:\n",
        "  - **Title**\n",
        "  - **Body**\n",
        "  - **Author**\n",
        "  - **Upvotes**\n",
        "  - **Number of comments**\n",
        "  - **Timestamp of creation**\n",
        "  - **Collection timestamp**\n",
        "- Skips **stickied posts**  \n",
        "- Handles **errors** gracefully to prevent crashes  \n",
        "- Combines new and existing data while **removing duplicates**  \n",
        "- Keeps only the **latest 1000 posts**  \n",
        "- Saves data to **CSV** (`reddit_live_data.csv`)  \n",
        "- Prints **summary statistics** including total posts and date range  \n",
        "\n",
        "---\n",
        "\n",
        "## Scheduler\n",
        "\n",
        "- Uses **APScheduler** to run the scraping job automatically every **60 minutes**  \n",
        "- First run is executed immediately on script start  \n",
        "- Scheduler continues to run in the **background**, keeping the main thread alive  \n",
        "- Can be stopped safely using **Ctrl+C**\n",
        "\n",
        "---\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "- **Python 3.x**  \n",
        "- **PRAW** â€“ Python Reddit API Wrapper  \n",
        "- **Pandas** â€“ Data handling  \n",
        "- **APScheduler** â€“ Background scheduling  \n",
        "- **python-dotenv** â€“ Load environment variables from `.env`  \n",
        "\n",
        "---\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Create a `.env` file with your Reddit API credentials:\n",
        "   - `REDDIT_CLIENT_ID`  \n",
        "   - `REDDIT_SECRET`  \n",
        "   - `REDDIT_USER_AGENT`  \n",
        "\n",
        "2. Run the script to **fetch and store Reddit posts continuously**.\n",
        "\n",
        "3. Access the saved CSV file (`reddit_live_data.csv`) for further **analysis or visualization**.\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** The scraper is designed to run safely over long periods, keeping only the **most recent posts** to avoid excessive storage.\n"
      ],
      "metadata": {
        "id": "dEHQehYoMM1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from apscheduler.schedulers.background import BackgroundScheduler\n",
        "import praw\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load Reddit credentials\n",
        "load_dotenv()\n",
        "CLIENT_ID = os.getenv(\"REDDIT_CLIENT_ID\")\n",
        "CLIENT_SECRET = os.getenv(\"REDDIT_SECRET\")\n",
        "USER_AGENT = os.getenv(\"REDDIT_USER_AGENT\")\n",
        "\n",
        "reddit = praw.Reddit(client_id=CLIENT_ID,\n",
        "                     client_secret=CLIENT_SECRET,\n",
        "                     user_agent=USER_AGENT)\n",
        "reddit.read_only = True\n",
        "\n",
        "def fetch_reddit_posts():\n",
        "    \"\"\"Fetch and save Reddit posts with error handling\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    print(f\"[{timestamp}] Starting data collection...\")\n",
        "\n",
        "    try:\n",
        "        subreddits = [\"technology\", \"mentalhealth\", \"AskReddit\"]\n",
        "        posts_per_subreddit = 20\n",
        "        all_posts = []\n",
        "\n",
        "        for sub in subreddits:\n",
        "            try:\n",
        "                print(f\"  â†’ Fetching from r/{sub}\")\n",
        "                for post in reddit.subreddit(sub).hot(limit=posts_per_subreddit + 5):\n",
        "                    if post.stickied:\n",
        "                        continue\n",
        "\n",
        "                    all_posts.append({\n",
        "                        \"subreddit\": sub,\n",
        "                        \"title\": post.title,\n",
        "                        \"body\": post.selftext if post.selftext else \"\",\n",
        "                        \"author\": str(post.author) if post.author else \"[deleted]\",\n",
        "                        \"upvotes\": post.score,\n",
        "                        \"num_comments\": post.num_comments,\n",
        "                        \"timestamp\": datetime.utcfromtimestamp(post.created_utc),\n",
        "                        \"collected_at\": datetime.now()\n",
        "                    })\n",
        "\n",
        "            except Exception as sub_error:\n",
        "                print(f\"   Error fetching from r/{sub}: {str(sub_error)}\")\n",
        "                continue\n",
        "\n",
        "        # Create DataFrame from new posts\n",
        "        df_new = pd.DataFrame(all_posts)\n",
        "\n",
        "        output_file = \"reddit_live_data.csv\"\n",
        "\n",
        "        # Check if file exists and append data\n",
        "        if os.path.exists(output_file):\n",
        "            try:\n",
        "                existing_df = pd.read_csv(output_file)\n",
        "\n",
        "                # Convert timestamp strings to datetime\n",
        "                if 'timestamp' in existing_df.columns:\n",
        "                    existing_df['timestamp'] = pd.to_datetime(existing_df['timestamp'])\n",
        "\n",
        "                if 'collected_at' in existing_df.columns:\n",
        "                    existing_df['collected_at'] = pd.to_datetime(existing_df['collected_at'])\n",
        "\n",
        "                # Combine old and new data\n",
        "                df_combined = pd.concat([existing_df, df_new], ignore_index=True)\n",
        "\n",
        "                # Remove duplicates (based on title + timestamp)\n",
        "                df_combined = df_combined.drop_duplicates(\n",
        "                    subset=['title', 'timestamp'],\n",
        "                    keep='last'\n",
        "                )\n",
        "\n",
        "                # Sort by timestamp (descending)\n",
        "                df_combined = df_combined.sort_values('timestamp', ascending=False)\n",
        "\n",
        "                # Keep only latest 1000 posts\n",
        "                if len(df_combined) > 1000:\n",
        "                    df_combined = df_combined.head(1000)\n",
        "\n",
        "                # Use combined data\n",
        "                df_final = df_combined\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   Error processing existing file, using new data only: {str(e)}\")\n",
        "                df_final = df_new\n",
        "        else:\n",
        "            # File doesn't exist, use only new data\n",
        "            df_final = df_new\n",
        "\n",
        "        # Save to CSV\n",
        "        df_final.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f\"   Data saved to {output_file}\")\n",
        "        print(f\"   Total posts: {len(df_final)}\")\n",
        "\n",
        "        # Display date range only if we have data\n",
        "        if len(df_final) > 0 and 'timestamp' in df_final.columns:\n",
        "            try:\n",
        "                min_date = df_final['timestamp'].min()\n",
        "                max_date = df_final['timestamp'].max()\n",
        "                print(f\"   Date range: {min_date} to {max_date}\")\n",
        "            except:\n",
        "                pass  # Skip if there's an error with date formatting\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[{datetime.now()}]  Error in fetch_reddit_posts: {str(e)}\")\n",
        "\n",
        "# Simple scheduler setup\n",
        "scheduler = BackgroundScheduler()\n",
        "\n",
        "# Schedule the job\n",
        "scheduler.add_job(\n",
        "    func=fetch_reddit_posts,\n",
        "    trigger='interval',\n",
        "    minutes=60,\n",
        "    id='reddit_scraper',\n",
        "    name='Reddit Data Scraper',\n",
        "    replace_existing=True\n",
        ")\n",
        "\n",
        "# Run immediately and start scheduler\n",
        "print(\" Reddit Real-Time Data Scraper\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# First run\n",
        "fetch_reddit_posts()\n",
        "\n",
        "# Start scheduler\n",
        "scheduler.start()\n",
        "print(\" Scheduler started successfully!\")\n",
        "\n",
        "if scheduler.get_jobs():\n",
        "    print(f\" Next run: {scheduler.get_jobs()[0].next_run_time}\")\n",
        "\n",
        "print(\"\\nPress Ctrl+C to stop the scheduler\\n\")\n",
        "\n",
        "# Keep main thread alive\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n Stopping scheduler...\")+\n",
        "    scheduler.shutdown(wait=False)\n",
        "    print(\" Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3TPN6LUw_JM",
        "outputId": "49f8aea4-75fa-406d-9ae7-713b5018be4c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Reddit Real-Time Data Scraper\n",
            "========================================\n",
            "[2025-12-02 21:25:16] Starting data collection...\n",
            "  â†’ Fetching from r/technology\n",
            "  â†’ Fetching from r/mentalhealth\n",
            "  â†’ Fetching from r/AskReddit\n",
            "   Data saved to reddit_live_data.csv\n",
            "   Total posts: 75\n",
            "   Date range: 2025-12-01 14:32:16 to 2025-12-02 21:23:15\n",
            " Scheduler started successfully!\n",
            " Next run: 2025-12-02 22:25:16.873763+00:00\n",
            "\n",
            "Press Ctrl+C to stop the scheduler\n",
            "\n",
            "\n",
            " Stopping scheduler...\n",
            " Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMhVtnFi-d7P",
        "outputId": "25ff3f2e-c1f3-4f39-acc2-fc4871519a61"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit pandas plotly numpy textblob praw python-dotenv\n",
        "\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLOT3LJS-iXe",
        "outputId": "6514245a-bee0-4b40-c960-32749a9cc974"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.12/dist-packages (7.8.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.12/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.12/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from praw) (1.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.51.0\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run these commands in your notebook/code cell:\n",
        "\n",
        "# 1. Install Streamlit\n",
        "!pip install streamlit\n",
        "\n",
        "# 2. Install other dependencies\n",
        "!pip install pandas plotly numpy\n",
        "\n",
        "# 3. Install TextBlob for sentiment analysis\n",
        "!pip install textblob\n",
        "\n",
        "# 4. Install Reddit API wrapper\n",
        "!pip install praw\n",
        "\n",
        "# 5. Install environment variable manager\n",
        "!pip install python-dotenv\n",
        "\n",
        "# 6. Download TextBlob data\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w_1aN1W_Exf",
        "outputId": "a34b88b9-4a8f-487d-899c-632d4bd2b0af"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.12/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.12/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.12/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from praw) (1.9.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from prawcore<3,>=2.4->praw) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.11.12)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run these commands in your notebook/code cell:\n",
        "\n",
        "# 1. Install Streamlit\n",
        "!pip install streamlit\n",
        "\n",
        "# 2. Install other dependencies\n",
        "!pip install pandas plotly numpy\n",
        "\n",
        "# 3. Install TextBlob for sentiment analysis\n",
        "!pip install textblob\n",
        "\n",
        "# 4. Install Reddit API wrapper\n",
        "!pip install praw\n",
        "\n",
        "# 5. Install environment variable manager\n",
        "!pip install python-dotenv\n",
        "\n",
        "# 6. Download TextBlob data\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoSL0veg_N_Q",
        "outputId": "04beba5d-e87d-4aa0-b3ae-4da12e9bbc9b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.12/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.12/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.12/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.12/dist-packages (from praw) (1.9.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from prawcore<3,>=2.4->praw) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.11.12)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Reddit Sentiment Dashboard\",\n",
        "    page_icon=\"ğŸ“Š\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Custom CSS for styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    .main-header {\n",
        "        font-size: 2.8rem;\n",
        "        color: #FF5700;\n",
        "        text-align: center;\n",
        "        margin-bottom: 1rem;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.5rem;\n",
        "        color: #1E88E5;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        padding: 1.5rem;\n",
        "        border-radius: 15px;\n",
        "        color: white;\n",
        "        text-align: center;\n",
        "        box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "    }\n",
        "    .stButton > button {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        color: white;\n",
        "        border: none;\n",
        "        padding: 0.5rem 2rem;\n",
        "        border-radius: 25px;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Title\n",
        "st.markdown('<h1 class=\"main-header\">ğŸ“Š Reddit Real-Time Sentiment Dashboard</h1>', unsafe_allow_html=True)\n",
        "st.markdown('<p style=\"text-align: center; color: #666; font-size: 1.1rem;\">Monitor sentiment trends across Reddit communities in real-time</p>', unsafe_allow_html=True)\n",
        "\n",
        "# Sidebar\n",
        "with st.sidebar:\n",
        "    st.markdown('<h2 class=\"sub-header\">âš™ï¸ Dashboard Controls</h2>', unsafe_allow_html=True)\n",
        "\n",
        "    # File selection\n",
        "    data_files = [f for f in os.listdir('.') if f.endswith('.csv') and 'reddit' in f.lower()]\n",
        "    selected_file = st.selectbox(\n",
        "        \"ğŸ“ Select Data File\",\n",
        "        data_files,\n",
        "        index=0 if data_files else None\n",
        "    )\n",
        "\n",
        "    # Auto-refresh toggle\n",
        "    auto_refresh = st.toggle(\"ğŸ”„ Auto-refresh every 30 seconds\", value=False)\n",
        "\n",
        "    # Sentiment analysis options\n",
        "    st.markdown(\"### ğŸ“Š Analysis Settings\")\n",
        "    analyze_sentiment = st.checkbox(\"Perform sentiment analysis\", value=True)\n",
        "\n",
        "    # Date range filter\n",
        "    st.markdown(\"### ğŸ“… Date Range\")\n",
        "    date_range = st.date_input(\n",
        "        \"Select date range\",\n",
        "        value=[datetime.now() - timedelta(days=7), datetime.now()],\n",
        "        max_value=datetime.now()\n",
        "    )\n",
        "\n",
        "    # Subreddit filter\n",
        "    st.markdown(\"### ğŸŒ Subreddit Filter\")\n",
        "    all_subreddits = st.checkbox(\"Select all subreddits\", value=True)\n",
        "\n",
        "    # Refresh button\n",
        "    if st.button(\"ğŸ”„ Refresh Data\", use_container_width=True):\n",
        "        st.rerun()\n",
        "\n",
        "# Data loading function\n",
        "@st.cache_data(ttl=30 if auto_refresh else 300)\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load and process data\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Convert timestamp columns\n",
        "        if 'timestamp' in df.columns:\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "        if 'collected_at' in df.columns:\n",
        "            df['collected_at'] = pd.to_datetime(df['collected_at'])\n",
        "\n",
        "        # Add sentiment if not present\n",
        "        if 'title_sentiment' not in df.columns and analyze_sentiment:\n",
        "            df['title_sentiment'] = df['title'].apply(\n",
        "                lambda x: TextBlob(str(x)).sentiment.polarity\n",
        "            )\n",
        "            # Categorize sentiment\n",
        "            df['sentiment_category'] = df['title_sentiment'].apply(\n",
        "                lambda x: 'positive' if x > 0.1 else ('negative' if x < -0.1 else 'neutral')\n",
        "            )\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading data: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Main dashboard logic\n",
        "if selected_file:\n",
        "    df = load_data(selected_file)\n",
        "\n",
        "    if not df.empty:\n",
        "        # Apply filters\n",
        "        if len(date_range) == 2:\n",
        "            mask = (df['timestamp'].dt.date >= date_range[0]) & (df['timestamp'].dt.date <= date_range[1])\n",
        "            df = df[mask]\n",
        "\n",
        "        if not all_subreddits and 'subreddit' in df.columns:\n",
        "            selected_subs = st.multiselect(\n",
        "                \"Select specific subreddits\",\n",
        "                df['subreddit'].unique(),\n",
        "                default=df['subreddit'].unique()[:3]\n",
        "            )\n",
        "            if selected_subs:\n",
        "                df = df[df['subreddit'].isin(selected_subs)]\n",
        "\n",
        "        # Metrics row\n",
        "        col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "        with col1:\n",
        "            st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
        "            st.metric(\"Total Posts\", len(df), delta=f\"{len(df):,}\")\n",
        "            st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        with col2:\n",
        "            if 'upvotes' in df.columns:\n",
        "                avg_upvotes = df['upvotes'].mean()\n",
        "                st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
        "                st.metric(\"Avg Upvotes\", f\"{avg_upvotes:.0f}\")\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        with col3:\n",
        "            if 'num_comments' in df.columns:\n",
        "                avg_comments = df['num_comments'].mean()\n",
        "                st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
        "                st.metric(\"Avg Comments\", f\"{avg_comments:.0f}\")\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        with col4:\n",
        "            if 'sentiment_category' in df.columns:\n",
        "                sentiment_score = df[df['sentiment_category'] == 'positive'].shape[0] - df[df['sentiment_category'] == 'negative'].shape[0]\n",
        "                st.markdown('<div class=\"metric-card\">', unsafe_allow_html=True)\n",
        "                st.metric(\"Sentiment Score\", sentiment_score)\n",
        "                st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "        # Tabs for different visualizations\n",
        "        tab1, tab2, tab3, tab4 = st.tabs([\"ğŸ“ˆ Sentiment Analysis\", \"ğŸ“Š Subreddit Stats\", \"ğŸ”¥ Top Content\", \"ğŸ“‹ Raw Data\"])\n",
        "\n",
        "        with tab1:\n",
        "            if 'sentiment_category' in df.columns:\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    # Sentiment distribution pie chart\n",
        "                    sentiment_counts = df['sentiment_category'].value_counts()\n",
        "                    fig1 = px.pie(\n",
        "                        values=sentiment_counts.values,\n",
        "                        names=sentiment_counts.index,\n",
        "                        title=\"Sentiment Distribution\",\n",
        "                        color=sentiment_counts.index,\n",
        "                        color_discrete_map={\n",
        "                            'positive': '#00CC96',\n",
        "                            'negative': '#EF553B',\n",
        "                            'neutral': '#636EFA'\n",
        "                        },\n",
        "                        hole=0.3\n",
        "                    )\n",
        "                    fig1.update_traces(textposition='inside', textinfo='percent+label')\n",
        "                    st.plotly_chart(fig1, use_container_width=True)\n",
        "\n",
        "                with col2:\n",
        "                    # Sentiment over time\n",
        "                    if len(df) > 10:\n",
        "                        sentiment_time = df.groupby([df['timestamp'].dt.date, 'sentiment_category']).size().reset_index(name='count')\n",
        "                        fig2 = px.line(\n",
        "                            sentiment_time,\n",
        "                            x='timestamp',\n",
        "                            y='count',\n",
        "                            color='sentiment_category',\n",
        "                            title=\"Sentiment Trends Over Time\",\n",
        "                            markers=True,\n",
        "                            color_discrete_map={\n",
        "                                'positive': '#00CC96',\n",
        "                                'negative': '#EF553B',\n",
        "                                'neutral': '#636EFA'\n",
        "                            }\n",
        "                        )\n",
        "                        st.plotly_chart(fig2, use_container_width=True)\n",
        "\n",
        "        with tab2:\n",
        "            if 'subreddit' in df.columns:\n",
        "                col1, col2 = st.columns(2)\n",
        "\n",
        "                with col1:\n",
        "                    # Posts by subreddit\n",
        "                    subreddit_counts = df['subreddit'].value_counts().head(10)\n",
        "                    fig3 = px.bar(\n",
        "                        x=subreddit_counts.index,\n",
        "                        y=subreddit_counts.values,\n",
        "                        title=\"Top Subreddits by Post Count\",\n",
        "                        labels={'x': 'Subreddit', 'y': 'Post Count'},\n",
        "                        color=subreddit_counts.values,\n",
        "                        color_continuous_scale='Viridis'\n",
        "                    )\n",
        "                    st.plotly_chart(fig3, use_container_width=True)\n",
        "\n",
        "                with col2:\n",
        "                    # Engagement by subreddit\n",
        "                    if 'upvotes' in df.columns:\n",
        "                        engagement = df.groupby('subreddit').agg({\n",
        "                            'upvotes': 'mean',\n",
        "                            'num_comments': 'mean'\n",
        "                        }).round(1).head(10)\n",
        "\n",
        "                        fig4 = go.Figure(data=[\n",
        "                            go.Bar(name='Avg Upvotes', x=engagement.index, y=engagement['upvotes']),\n",
        "                            go.Bar(name='Avg Comments', x=engagement.index, y=engagement['num_comments'])\n",
        "                        ])\n",
        "                        fig4.update_layout(\n",
        "                            title=\"Engagement by Subreddit\",\n",
        "                            barmode='group',\n",
        "                            xaxis_title=\"Subreddit\",\n",
        "                            yaxis_title=\"Count\"\n",
        "                        )\n",
        "                        st.plotly_chart(fig4, use_container_width=True)\n",
        "\n",
        "        with tab3:\n",
        "            # Top posts table\n",
        "            st.subheader(\"ğŸ”¥ Top Performing Posts\")\n",
        "\n",
        "            if 'upvotes' in df.columns:\n",
        "                top_posts = df.nlargest(15, 'upvotes')[['title', 'subreddit', 'upvotes', 'num_comments', 'timestamp']]\n",
        "                top_posts['timestamp'] = top_posts['timestamp'].dt.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "                # Format as HTML table with styling\n",
        "                st.dataframe(\n",
        "                    top_posts.style.background_gradient(subset=['upvotes'], cmap='Greens'),\n",
        "                    use_container_width=True,\n",
        "                    height=400\n",
        "                )\n",
        "\n",
        "        with tab4:\n",
        "            # Raw data explorer\n",
        "            st.subheader(\"ğŸ“‹ Data Explorer\")\n",
        "\n",
        "            # Search functionality\n",
        "            search_term = st.text_input(\"ğŸ” Search in titles:\")\n",
        "            if search_term:\n",
        "                filtered_df = df[df['title'].str.contains(search_term, case=False, na=False)]\n",
        "            else:\n",
        "                filtered_df = df\n",
        "\n",
        "            # Column selector\n",
        "            available_columns = filtered_df.columns.tolist()\n",
        "            selected_columns = st.multiselect(\n",
        "                \"Select columns to display\",\n",
        "                available_columns,\n",
        "                default=available_columns[:min(8, len(available_columns))]\n",
        "            )\n",
        "\n",
        "            if selected_columns:\n",
        "                st.dataframe(filtered_df[selected_columns], use_container_width=True, height=400)\n",
        "\n",
        "            # Data summary\n",
        "            with st.expander(\"ğŸ“Š Data Summary\"):\n",
        "                col1, col2 = st.columns(2)\n",
        "                with col1:\n",
        "                    st.write(\"**Data Shape:**\", df.shape)\n",
        "                    st.write(\"**Time Range:**\", df['timestamp'].min(), \"to\", df['timestamp'].max())\n",
        "                with col2:\n",
        "                    st.write(\"**Missing Values:**\")\n",
        "                    missing = df.isnull().sum()\n",
        "                    for col, count in missing[missing > 0].items():\n",
        "                        st.write(f\"  - {col}: {count}\")\n",
        "\n",
        "            # Download button\n",
        "            csv = df.to_csv(index=False)\n",
        "            st.download_button(\n",
        "                label=\"ğŸ“¥ Download CSV\",\n",
        "                data=csv,\n",
        "                file_name=f\"reddit_data_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "                mime=\"text/csv\",\n",
        "                use_container_width=True\n",
        "            )\n",
        "\n",
        "        # Auto-refresh logic\n",
        "        if auto_refresh:\n",
        "            st.write(f\"ğŸ”„ Next auto-refresh in 30 seconds...\")\n",
        "            time.sleep(30)\n",
        "            st.rerun()\n",
        "\n",
        "    else:\n",
        "        st.warning(\"âš ï¸ No data found in the selected file. Please ensure data has been collected.\")\n",
        "\n",
        "        # Instructions for first-time setup\n",
        "        with st.expander(\"ğŸ”§ First-time setup instructions\"):\n",
        "            st.write(\"\"\"\n",
        "            1. **Run the Reddit scraper** to collect data:\n",
        "               ```bash\n",
        "               python realtime_scraper.py\n",
        "               ```\n",
        "\n",
        "            2. **Wait for data collection** (at least one cycle)\n",
        "\n",
        "            3. **Refresh this page** to see the data\n",
        "\n",
        "            4. **Select the CSV file** from the sidebar\n",
        "            \"\"\")\n",
        "\n",
        "        if st.button(\"ğŸ“– View Sample Data Structure\"):\n",
        "            sample_data = pd.DataFrame({\n",
        "                'title': ['Sample Post 1', 'Sample Post 2'],\n",
        "                'subreddit': ['AskReddit', 'technology'],\n",
        "                'upvotes': [100, 250],\n",
        "                'num_comments': [25, 50],\n",
        "                'timestamp': [datetime.now(), datetime.now() - timedelta(hours=1)],\n",
        "                'sentiment_category': ['positive', 'neutral']\n",
        "            })\n",
        "            st.dataframe(sample_data)\n",
        "else:\n",
        "    st.error(\"âŒ No data files found. Please run the Reddit scraper first.\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "col1, col2, col3 = st.columns([1, 2, 1])\n",
        "with col2:\n",
        "    st.markdown(\"\"\"\n",
        "    <div style=\"text-align: center; color: #666;\">\n",
        "    <p><strong>ğŸš€ Reddit Sentiment Analysis Dashboard</strong></p>\n",
        "    <p>Powered by Streamlit, Plotly & Reddit API</p>\n",
        "    <p>Last updated: {}</p>\n",
        "    </div>\n",
        "    \"\"\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")), unsafe_allow_html=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXpbxiFu-GM9",
        "outputId": "72729a7c-a59b-4073-abdb-eac42c7d3c58"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-02 21:35:28.680 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.682 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.804 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-12-02 21:35:28.805 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.816 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.817 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.818 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.820 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.823 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.824 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.826 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.827 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.828 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.830 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.831 Session state does not function when running a script without `streamlit run`\n",
            "2025-12-02 21:35:28.832 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.833 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.834 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.836 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.837 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.839 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.841 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.842 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.843 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.845 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.846 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.850 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.851 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.852 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.855 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.859 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.861 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.863 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.867 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.870 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.871 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.872 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.873 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.874 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.875 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.883 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.892 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.895 No runtime found, using MemoryCacheStorageManager\n",
            "2025-12-02 21:35:28.899 No runtime found, using MemoryCacheStorageManager\n",
            "2025-12-02 21:35:28.900 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.903 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.947 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.956 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.963 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.964 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.971 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.979 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.980 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.992 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.993 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.995 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:28.996 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.003 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.005 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.007 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.008 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.009 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.010 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.011 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.012 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.014 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.014 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.016 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.017 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.018 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.948 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 21:35:29.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:29.970 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.191 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 21:35:30.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.572 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 21:35:30.578 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.582 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.585 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.586 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.628 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 21:35:30.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.645 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.662 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.665 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.671 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.680 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:30.988 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 21:35:30.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.105 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.109 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.116 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.123 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.126 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.140 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.143 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.148 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.152 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.163 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.176 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.185 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.191 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-12-02 21:35:31.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.250 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.259 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.270 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.291 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.342 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.348 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.412 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-12-02 21:35:31.416 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}